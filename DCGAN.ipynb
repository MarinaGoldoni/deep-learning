{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<figure>\n",
        "<img src='data:image/png;base64,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'  width=\"120\" />\n",
        "<figcaption></figure>\n",
        "\n",
        "# Deep Learning"
      ],
      "metadata": {
        "id": "hzZQkjoD_dWH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF2x3qooyBTI"
      },
      "source": [
        "### Deep Convolutional Generative Adversarial Network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective\n",
        "\n",
        "The objective of this notebook is to implement and train a Generative Adversarial Network (GAN) using the CIFAR dataset. The aim is to construct a model where the generator creates images from noise, and the discriminator classifies these images as real or fake. The training process involves alternating between updating the generator and discriminator to improve their performance iteratively. By the end of the training, the goal is to have a GAN capable of generating realistic images that closely resemble those in the CIFAR dataset.\n",
        "\n",
        "CIFAR-10 Database: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "metadata": {
        "id": "8_UvPG9w_pqC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "Let's load the libraries that we will use for the challenge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZKbyU2-AiY-"
      },
      "outputs": [],
      "source": [
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Other libraries\n",
        "import os\n",
        "import PIL\n",
        "import time\n",
        "import glob\n",
        "import imageio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzTlj4YdCip_"
      },
      "outputs": [],
      "source": [
        "# Library for GIFs generetion\n",
        "!pip install -q imageio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "## 2. Data Loading and Preprocessig\n",
        "\n",
        "Let's use the CIFAR dataset to train the generator and the discriminator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL_lHBE7wEDk"
      },
      "outputs": [],
      "source": [
        "tfds.list_builders()\n",
        "builder = tfds.builder(\"cifar10\")\n",
        "builder.download_and_prepare()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c_zoX86xeu1"
      },
      "outputs": [],
      "source": [
        "print(builder.info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_TDCUzE0AoR"
      },
      "outputs": [],
      "source": [
        "(train_dataset_raw) = builder.as_dataset(split=\"train\", as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CGjcRM50N7C"
      },
      "outputs": [],
      "source": [
        "def format_example(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  # scale from [0,255] to [-1,1]\n",
        "  image = (image - 127.5) / 127.5\n",
        "  image = tf.image.resize(image, (32, 32))\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBRXC7WR0h6e"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset_raw.map(format_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvjLBXIW5wUM"
      },
      "outputs": [],
      "source": [
        "for image, label in train_dataset.take(1):\n",
        "  plt.imshow(image, interpolation='nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVfwgtkZJrQx"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "for image, label in train_dataset.take(49):\n",
        "  # define subplot\n",
        "  plt.subplot(7, 7, 1 + i)\n",
        "  # turn off axis\n",
        "  plt.axis('off')\n",
        "  # plot raw pixel data\n",
        "  image = (image + 1) / 2.0\n",
        "  plt.imshow(image)\n",
        "  i = i + 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "## Model creation\n",
        "\n",
        "Both the generator and discriminator will be defined using the [Keras Sequential API](https://www.tensorflow.org/guide/keras#sequential_model)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tEyxE-GMC48"
      },
      "source": [
        "### Generator\n",
        "The generator uses `tf.keras.layers.Conv2DTranspose` (upsampling) layers to produce an image from a seed (random noise). It starts with a Dense layer that takes the seed as input, then upscales (upsamples) it several times until reaching the desired image size of 32x32x3. We will use `tf.keras.layers.LeakyReLU` activation layers, except for the output layer, which will use `tanh`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bpTcDqoLWjY"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((8, 8, 256)))\n",
        "    assert model.output_shape == (None, 8, 8, 256)\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 8, 8, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 16, 16, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 32, 32, 3)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLDOjaV8IrFE"
      },
      "outputs": [],
      "source": [
        "generator = make_generator_model()\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl7jcC7TdPTG"
      },
      "outputs": [],
      "source": [
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCSKexcxyuyN"
      },
      "outputs": [],
      "source": [
        "plt.imshow((generated_image[0, :, :, :] + 1) / 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0IKnaCtg6WE"
      },
      "source": [
        "### Discriminator\n",
        "\n",
        "The discriminator is an image classifier based on CNNs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw2tPLmk2pEP"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[32, 32, 3]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDkA05NE6QMs"
      },
      "outputs": [],
      "source": [
        "discriminator = make_discriminator_model()\n",
        "discriminator.summary()\n",
        "decision = discriminator(generated_image)\n",
        "print(decision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FMYgY_mPfTi"
      },
      "source": [
        "### Definition of the Cost Function and Optimizer\n",
        "\n",
        "We define the cost function and optimizers for both models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psQfmXxYKU3X"
      },
      "outputs": [],
      "source": [
        "# This method returns a helper function to calculate cross-entropy loss.\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKY_iPSPNWoj"
      },
      "source": [
        "#### Discriminator Cost Function\n",
        "\n",
        "This method quantifies how well the discriminator is able to distinguish between real and fake images. It compares the predictions of real images with an array of 1s, and the predictions of fake images with an array of 0s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkMNfBWlT-PV"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd-3GCUEiKtv"
      },
      "source": [
        "#### Generator Cost Function\n",
        "\n",
        "The generator's cost function quantifies how well it can deceive the discriminator. Intuitively, if the generator performs well, the discriminator will be fooled. Here, we compare the discriminator's decisions on fake images with an array of 1s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90BIcCKcDMxz"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgIc7i0th_Iu"
      },
      "source": [
        "The discriminator and generator will have separate optimizers since we will train these networks independently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWCn_PVdEJZ7"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWtinsGDPJlV"
      },
      "source": [
        "### Save Checkpoints\n",
        "\n",
        "This notebook also demonstrates how to save and restore models, which can be very useful in case training is paused or if we want to use the models later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA1w-7s2POEy"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "## Defining the Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS2GWywBbAWo"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 49\n",
        "\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jylSonrqSWfi"
      },
      "source": [
        "The training loop starts with the generator receiving a random seed as input. This seed is used to produce an image. The discriminator is then used to classify real images (from the dataset) and fake images (produced by the generator). The cost is calculated for each network separately, and the weights are updated using gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t5ibNo05jCB"
      },
      "outputs": [],
      "source": [
        "# Here we use tf.function\n",
        "# This compiles the function.\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M7LmLtGEMQJ"
      },
      "outputs": [],
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch, label_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF on the fly\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator, epoch + 1, seed)\n",
        "\n",
        "    # Save the model every 20 epochs\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
        "\n",
        "  # Generate after each epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator, epochs, seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aFF7Hk3XdeW"
      },
      "source": [
        "### Generating and saving images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmdVsmvhPxyy"
      },
      "outputs": [],
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    # Note that `training` is set to False.\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(7,7))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(7, 7, 1 + i)\n",
        "        image = (predictions[i, :, :, :] + 1) / 2.0\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()\n",
        "\n",
        "# Training loop\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for image_batch, label_batch in dataset:\n",
        "            train_step(image_batch)\n",
        "\n",
        "        # Produce images for the GIF on the fly\n",
        "        display.clear_output(wait=True)\n",
        "        generate_and_save_images(generator, epoch + 1, seed)\n",
        "\n",
        "        # Save the model every 20 epochs\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
        "\n",
        "    # Generate after each epoch\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator, epochs, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZrd4CdjR-Fp"
      },
      "source": [
        "## Training the Model\n",
        "\n",
        "We call the previously defined `train()` function to simultaneously train the generator and the discriminator. Training GANs is complex, and it's important that the generator and the discriminator do not significantly outperform each other (both should train at a similar pace).\n",
        "\n",
        "At the beginning of the training, the generated images will look like random noise. As training progresses, the generated digits will start to look more real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ly3UN0SLLY2l"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 50000\n",
        "BATCH_SIZE = 256\n",
        "train_dataset_shuffled = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "train(train_dataset_shuffled, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhXsd0srPo8c"
      },
      "outputs": [],
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4M_vIbUi7c0"
      },
      "source": [
        "## GIF creation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfO5wCdclHGL"
      },
      "outputs": [],
      "source": [
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x3q9_Oe5q0A"
      },
      "outputs": [],
      "source": [
        "display_image(EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NywiH3nL8guF"
      },
      "source": [
        "We use `imageio` to create an animated GIF with these images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGKQgENQ8lEI"
      },
      "outputs": [],
      "source": [
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "import IPython\n",
        "if IPython.version_info > (6,2,0,''):\n",
        "  display.Image(filename=anim_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGhC3-fMWSwl"
      },
      "source": [
        "If you are working on Colab, its possible to download it with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV0yiKpzNP1b"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(anim_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}